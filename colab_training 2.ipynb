{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "colab training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2YbXveSwoQq"
      },
      "source": [
        "#This is my Google Colab script for training and evaluation of the models.; Faster R-CNN, SSD MobileNet Resnet 50 + 152.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeR7U0x5vNI8"
      },
      "source": [
        "#Mounting data from Tensorflow folder saved in my Google Drive.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToP5xmZA5a1S"
      },
      "source": [
        "#Updating libraries required for training and evaluation of models.\n",
        "\n",
        "\n",
        "!apt-get update --fix-missing\n",
        "!pip install -q pycocotools\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhbGnlAt6maV"
      },
      "source": [
        "#Setting up the Protobuff libraries that will also be utilised.\n",
        "\n",
        "%cd '/content/gdrive/My Drive/TensorFlow/models/research/'\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdaLQNQs7NoV"
      },
      "source": [
        "#creating the environment that will be used for training/evaluation.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "os.environ['PYTHONPATH']+=\":/content/gdrive/My Drive/TensorFlow/models\"\n",
        "sys.path.append(\"/content/gdrive/My Drive/TensorFlow/models/research\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3OjAu1i7fJa"
      },
      "source": [
        "#running the built in tensorflow file  - setup.py\n",
        "\n",
        "!python setup.py build\n",
        "!python setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLf7T2mmjWH2"
      },
      "source": [
        "#This command shows us the gpu that is being used in the current Colab Environment.\n",
        "#Shows the specific gpu mopdel and the amnount of VRAM available for use. Usually TESLA T4\n",
        "\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJkyEWbJ8GDQ"
      },
      "source": [
        "#Testing the installation of tensorflow on the Colab system and also importing the object detection modules.\n",
        "\n",
        "%cd '/content/gdrive/My Drive/TensorFlow/models/research/object_detection/builders/'\n",
        "!python model_builder_tf2_test.py\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eqt5vQp-YXM"
      },
      "source": [
        "#training cell for each model.\n",
        "\n",
        "#Models used in training:\n",
        "# my_faster_rcnn_resnet152_v1_800x1333_coco17_tpu-8\n",
        "# my_faster_rcnn_resnet50_v1_800x1333_coco17_tpu-8\n",
        "# my_ssd_resnet50_v1_fpn_1024x1024_coco17_tpu-8\n",
        "# my_ssd_resnet152_v1_fpn_1024x1024_coco17_tpu-8\n",
        "\n",
        "%cd '/content/gdrive/My Drive/TensorFlow/workspace/training_demo'\n",
        "!python model_main_tf2.py --model_dir=models/my_faster_rcnn_resnet152_v1_800x1333_coco17_tpu-8 --pipeline_config_path=models/my_faster_rcnn_resnet152_v1_800x1333_coco17_tpu-8/pipeline.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7saIJgti8nIk"
      },
      "source": [
        "# Opening up tensorboard to monitor the progress of the models being trained and also monitoring the evaluation of each model.\n",
        "\n",
        "#move into working directory.\n",
        "%cd '/content/gdrive/My Drive/TensorFlow/workspace/training_demo'\n",
        "#load tensorboard and specify folder for evaluation\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=models/my_faster_rcnn_resnet152_v1_800x1333_coco17_tpu-8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phqnuzr7m6oO"
      },
      "source": [
        "#This is where evaluation of the checkpoints from each trained model occurs. \n",
        "#Can change which checkpoint is evaluated by editing \"modal_checkpoint path\" value in the checkpoint file in each model.\n",
        "\n",
        "%cd '/content/gdrive/My Drive/TensorFlow/workspace/training_demo'\n",
        "!python model_main_tf2.py --model_dir=exported-models/faster_rcnn_resnet152_final --pipeline_config_path=exported-models/faster_rcnn_resnet152_final/pipeline.config --checkpoint_dir=exported-models/faster_rcnn_resnet152_final/checkpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8INltFDx-M-"
      },
      "source": [
        "#Exporting the completed trained model and saving to exported-model\n",
        "\n",
        "%cd '/content/gdrive/My Drive/TensorFlow/workspace/training_demo'\n",
        "!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path ./models/my_faster_rcnn_resnet152_v1_800x1333_coco17_tpu-8/pipeline.config --trained_checkpoint_dir ./models/my_faster_rcnn_resnet152_v1_800x1333_coco17_tpu-8/ --output_directory ./exported-models/faster_rcnn_resnet152_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16Scz6M6WLHS"
      },
      "source": [
        "#using the completed models for object detection on test images\n",
        "\n",
        "%cd '/content/gdrive/My Drive/TensorFlow/workspace/training_demo'\n",
        "\n",
        "#importing libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# all the completed models for inference\n",
        "\n",
        "#'/content/gdrive/My Drive/TensorFlow/workspace/training_demo/exported-models/faster_rcnn_final/saved_model'\n",
        "#'/content/gdrive/My Drive/TensorFlow/workspace/training_demo/exported-models/ssd_resnet50_final/saved_model'\n",
        "#'/content/gdrive/My Drive/TensorFlow/workspace/training_demo/exported-models/ssd_resnet152_final/saved_model'\n",
        "\n",
        "\n",
        "#importing the assets required for inference (models used for inference)\n",
        "final_model_path = \"exported-models/ssd_resnet152_final/saved_model\"\n",
        "loaded_model = tf.saved_model.load(final_model_path)\n",
        "\n",
        "print(\"Model loading completed\")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqCnDR9pfNdF"
      },
      "source": [
        "#loading label map and converting into correct format for use in inference\n",
        "\n",
        "label_map_path = '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/annotations/label_map.pbtxt'\n",
        "\n",
        "# category index is an dict of catergory definitions for each class (id and name). in this case the class of each vehicle present in the images.\n",
        "category_index = label_map_util.create_category_index_from_labelmap(label_map_path, use_display_name=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT28ks7vfORA"
      },
      "source": [
        "#Loading the test images that will be used for inference.\n",
        "\n",
        "##Examples for images folder\n",
        "\n",
        "# SSDB00479.JPG - one car\n",
        "# SSDB00569.JPG - lots of cars\n",
        "# SSDB01287.JPG - lots of cars on a street\n",
        "# SSDB01659.JPG - two vans\n",
        "# 201936973_a7f65606a8_b.jpg - bus and cars\n",
        "# SSDB01634.JPG - truck and cars\n",
        "# SSDB01526.JPG - one van\n",
        "# SSDB01677.JPG - one van and cars\n",
        "# SSDB00442.JPG - multiple cars driving\n",
        "\n",
        "##########################\n",
        "\n",
        "\n",
        "##Final test images \n",
        "\n",
        "# \"images/final/1.jpg\",\"images/final/2.jpg\",\"images/final/3.jpg\",\"images/final/4.jpg\",\"images/final/5.jpg\",\"images/final/6.jpg\",\"images/final/7.jpg\",\"images/final/8.jpg\",\"images/final/9.jpg\",\"images/final/10.jpg\",\"images/final/11.jpg\",\"images/final/12.jpg\"\n",
        "# \"images/final/13.JPG\",\"images/final/14.JPG\",\"images/final/15.JPG\",\"images/final/16.JPG\",\"images/final/17.JPG\",\"images/final/18.JPG\",\"images/final/19.JPG\",\"images/final/20.JPG\",\"images/final/21.JPG\",\"images/final/22.JPG\",\"images/final/23.JPG\",\"images/final/24.JPG\",\"images/final/25.JPG\"\n",
        "\n",
        "\n",
        "#test_images = [\"images/test/SSDB01677.JPG\",\"images/test/SSDB01659.JPG\", \"images/test/SSDB00442.JPG\", \"images/test/SSDB01287.JPG\"]\n",
        "test_images = [\"images/final/13.JPG\",\"images/final/14.JPG\",\"images/final/15.JPG\",\"images/final/16.JPG\",\"images/final/17.JPG\",\"images/final/18.JPG\",\"images/final/19.JPG\",\"images/final/20.JPG\",\"images/final/21.JPG\",\"images/final/22.JPG\",\"images/final/23.JPG\",\"images/final/24.JPG\",\"images/final/25.JPG\"]\n",
        "print(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVaMQsYgjhLt",
        "collapsed": true
      },
      "source": [
        "#@title\n",
        "#Running the actual detection\n",
        "# This code allows me to utilise the final models that have been trained on a new dataset of images and compare performance using the results from this testing.\n",
        "\n",
        "\n",
        "%cd '/content/gdrive/My Drive/TensorFlow/workspace/training_demo'\n",
        "\n",
        "#loads the images in the test_images list above into an numpy array\n",
        "def image_numpy_array(path):\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "for image in test_images:\n",
        "  image_numpy=image_numpy_array(image)\n",
        "\n",
        "  #Here the images used converted into tensors which are required for the detection models.\n",
        "  tensor_convert=tf.convert_to_tensor(image_numpy)\n",
        "  #allows for use of multiple images at once.\n",
        "  tensor_convert=tensor_convert[tf.newaxis,...]\n",
        "\n",
        "  model_detection=loaded_model(tensor_convert)\n",
        "\n",
        "\n",
        "  num_detections=int(model_detection.pop('num_detections'))\n",
        "  model_detection={key:value[0,:num_detections].numpy()\n",
        "                    for key,value in model_detection.items()}\n",
        "  model_detection['num_detections']=num_detections\n",
        "\n",
        "  model_detection['detection_classes']= model_detection['detection_classes'].astype(np.int64)\n",
        "  \n",
        "  image_np_with_detections=image_numpy.copy()\n",
        "\n",
        "  #configuration of the image to be shown\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np_with_detections,         # the image to be shown\n",
        "            model_detection['detection_boxes'],    # shows the box for each prediction.\n",
        "            model_detection['detection_classes'],  # shows the class of each prediction.\n",
        "            model_detection['detection_scores'], #shows the accuracy score on each box.\n",
        "            category_index,           #using the label map categories\n",
        "            use_normalized_coordinates=True, # whether the boxes are also interpreted as coordinates.\n",
        "            line_thickness = 7,      # changes thickness of the lines.\n",
        "            max_boxes_to_draw=100,   #max number of boxes that will be drawn  .\n",
        "            min_score_thresh=.6,  #will only print boxes where accuracy is above 60%.\n",
        "            agnostic_mode=False)\n",
        "\n",
        "  print('Completed Detection for {}... '.format(image), end='')\n",
        "\n",
        "\n",
        "  # printing out the figures after configuration above.\n",
        "  %matplotlib inline\n",
        "  plt.figure()\n",
        "\n",
        "  # larger image printed out\n",
        "  plt.figure(figsize=(40,20)) \n",
        "  plt.imshow(image_np_with_detections)\n",
        "  plt.show()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}